{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db17a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add src to the sys path of this notebook\n",
    "import sys\n",
    "import pathlib\n",
    "sys.path.append(str(pathlib.Path().absolute().parent / \"src\"))\n",
    "from models.gru import GRUClassifier, CNN_GRUClassifier\n",
    "import data.paths as paths\n",
    "from data.load_data import list_logs\n",
    "from utils.config_loader import load_config\n",
    "from utils.seed import set_seed\n",
    "from data.sensor_dataset import SensorDataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb396f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window size: 2 s., downsampling freq.: 10 Hz\n",
      "Total logs for Forward direction: 98\n",
      "Training logs: 78, Testing logs: 20\n",
      "Final training shape: torch.Size([20, 1]) (window size s. * downsampling freq., number of sensor channels), Final testing shape: torch.Size([356, 1])\n"
     ]
    }
   ],
   "source": [
    "data_cfg_path, fit_cfg_path, model_cfg_path = paths.CONFIG_FOLDER / 'data' / 'base_forward.yml', paths.CONFIG_FOLDER / 'fit' / 'base_fit.yml', paths.CONFIG_FOLDER / 'model' / 'base_model_dropout.yml'\n",
    "data_cfg, fit_cfg, model_cfg = load_config(data_cfg_path, fit_cfg_path, model_cfg_path)\n",
    "\n",
    "print(f\"Window size: {data_cfg['window_size']} s., downsampling freq.: {data_cfg['downsampling_freq']} Hz\")\n",
    "\n",
    "RUN_ID = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "torch_generator = set_seed(data_cfg[\"seed\"])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load Data\n",
    "log_names = list_logs(paths.PAPER_EXPERIMENT_DATA_FOLDER)\n",
    "if data_cfg[\"direction\"] != \"Both\":\n",
    "    log_names = log_names[log_names[\"direction\"] == data_cfg[\"direction\"]].reset_index(drop=True)\n",
    "print(f\"Total logs for {data_cfg['direction']} direction: {len(log_names)}\")\n",
    "\n",
    "train_log_names, test_log_names = train_test_split(log_names, test_size=fit_cfg[\"test_size_ratio\"], random_state=data_cfg[\"seed\"])\n",
    "train_log_names = train_log_names.reset_index(drop=True)\n",
    "test_log_names = test_log_names.reset_index(drop=True)\n",
    "print(f\"Training logs: {len(train_log_names)}, Testing logs: {len(test_log_names)}\")\n",
    "train_dataset = SensorDataset(train_log_names, window_size=data_cfg[\"window_size\"], mode='train', downsampling_freq=data_cfg[\"downsampling_freq\"])\n",
    "test_dataset  = SensorDataset(test_log_names,  window_size=data_cfg[\"window_size\"], mode='eval', downsampling_freq=data_cfg[\"downsampling_freq\"], mean_force=train_dataset.mean_force, std_force=train_dataset.std_force)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=fit_cfg[\"batch_size\"], shuffle=True, generator=torch_generator)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1, shuffle=False, generator=torch_generator)\n",
    "\n",
    "print(f\"Final training shape: {train_dataset[0][0].shape} (window size s. * downsampling freq., number of sensor channels), Final testing shape: {test_dataset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a75484ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "num_channels = train_dataset[0][0].shape[1]  # number of sensor channels\n",
    "if model_cfg.get(\"cnn_channels\", None):\n",
    "    gru_model = CNN_GRUClassifier(input_size=num_channels, hidden_size=model_cfg[\"hidden_size\"], num_layers=model_cfg[\"num_layers\"], output_size=1, cnn_channels=model_cfg[\"cnn_channels\"], dropout=model_cfg[\"dropout\"]).to(device)\n",
    "else:\n",
    "    gru_model = GRUClassifier(input_size=num_channels, hidden_size=model_cfg[\"hidden_size\"], num_layers=model_cfg[\"num_layers\"], output_size=1, dropout=model_cfg[\"dropout\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382a5492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 20, 1]), Target shape: torch.Size([32, 1]), (Batch size: 32, Window size (samples): 20, Num channels: 1)\n"
     ]
    }
   ],
   "source": [
    "# get a batch of training data\n",
    "data_iter = iter(train_loader)\n",
    "inputs, targets = next(data_iter)\n",
    "inputs, targets = inputs.to(device), targets.to(device)\n",
    "print(f\"Input shape: {inputs.shape}, Target shape: {targets.shape}, (Batch size: {fit_cfg['batch_size']}, Window size (samples): {data_cfg['window_size'] * data_cfg['downsampling_freq']}, Num channels: {num_channels})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c53ce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 20, 1]), (Bacth size: 32, Sequence length: 20, Input size: 1)\n",
      "hidden state shape: torch.Size([2, 32, 16]), (Number of layers: 2, Batch size: 32, Hidden size: 16)\n",
      "GRU output shape: torch.Size([32, 20, 16]), (Batch size: 32, Sequence length: 20, Hidden size: 16)\n",
      "Fully connected output shape: torch.Size([32, 1]), (Batch size: 32, Output size: 1)\n"
     ]
    }
   ],
   "source": [
    "outputs = gru_model.forward(inputs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9e1dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Input shape: torch.Size([1, 356, 1]), Test Target shape: torch.Size([1, 356, 1]), (Batch size: 1, Window size (samples): 20, Num channels: 1)\n",
      "Input shape: torch.Size([1, 356, 1]), (Bacth size: 1, Sequence length: 356, Input size: 1)\n",
      "hidden state shape: torch.Size([2, 1, 16]), (Number of layers: 2, Batch size: 1, Hidden size: 16)\n",
      "GRU output shape: torch.Size([1, 356, 16]), (Batch size: 1, Sequence length: 356, Hidden size: 16)\n",
      "Fully connected output shape: torch.Size([1, 1]), (Batch size: 1, Output size: 1)\n"
     ]
    }
   ],
   "source": [
    "test_inputs, test_targets = next(iter(test_loader))\n",
    "test_inputs, test_targets = test_inputs.to(device), test_targets.to(device)\n",
    "print(f\"Test Input shape: {test_inputs.shape}, Test Target shape: {test_targets.shape}, (Batch size: 1, Window size (samples): {data_cfg['window_size'] * data_cfg['downsampling_freq']}, Num channels: {num_channels})\")\n",
    "test_outputs = gru_model.forward(test_inputs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fdd2190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "               GRU-1  [[-1, 50, 16], [-1, 2, 16]]               0\n",
      "            Linear-2                [-1, 50, 1]              17\n",
      "================================================================\n",
      "Total params: 17\n",
      "Trainable params: 17\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.19\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.20\n",
      "----------------------------------------------------------------\n",
      "Parameter: gru.weight_ih_l0, Shape: torch.Size([48, 1])\n",
      "Parameter: gru.weight_hh_l0, Shape: torch.Size([48, 16])\n",
      "Parameter: gru.bias_ih_l0, Shape: torch.Size([48])\n",
      "Parameter: gru.bias_hh_l0, Shape: torch.Size([48])\n",
      "Parameter: gru.weight_ih_l1, Shape: torch.Size([48, 16])\n",
      "Parameter: gru.weight_hh_l1, Shape: torch.Size([48, 16])\n",
      "Parameter: gru.bias_ih_l1, Shape: torch.Size([48])\n",
      "Parameter: gru.bias_hh_l1, Shape: torch.Size([48])\n",
      "Parameter: fc.weight, Shape: torch.Size([1, 16])\n",
      "Parameter: fc.bias, Shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# print model summary\n",
    "from torchsummary import summary\n",
    "summary(gru_model, input_size=(data_cfg[\"window_size\"] * data_cfg[\"downsampling_freq\"], num_channels))\n",
    "# print all parameters\n",
    "for name, param in gru_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Parameter: {name}, Shape: {param.data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff95d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 because GRU has hidden size 16 and 3 gates (reset, update, new hidden), so 16 * 3 = 48\n"
     ]
    }
   ],
   "source": [
    "print(f\"48 because GRU has hidden size {model_cfg['hidden_size']} and 3 gates (reset, update, new hidden), so 16 * 3 = 48\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1666578b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable scalar parameters: 2561, which is consistent with 2561\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in gru_model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable scalar parameters: {total_params}, which is consistent with {48*1+48*16+48+48+48*16+48*16+48+48+16+1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
